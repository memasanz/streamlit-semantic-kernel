{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Function Calling:\n",
    "https://devblogs.microsoft.com/semantic-kernel/planning-with-semantic-kernel-using-automatic-function-calling/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: if using a virtual environment, do not run this cell\n",
    "#%pip install -U semantic-kernel\n",
    "from semantic_kernel import __version__\n",
    "\n",
    "__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services import Service\n",
    "from service_settings import ServiceSettings\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.functions import KernelArguments\n",
    "\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.functions import kernel_function\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.connectors.ai.function_call_behavior import FunctionCallBehavior\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "from semantic_kernel.connectors.ai.chat_completion_client_base import ChatCompletionClientBase\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "from semantic_kernel.functions.kernel_arguments import KernelArguments\n",
    "from semantic_kernel.connectors.ai.open_ai.prompt_execution_settings.azure_chat_prompt_execution_settings import (\n",
    "    AzureChatPromptExecutionSettings,\n",
    ")\n",
    "\n",
    "import os\n",
    "from Plugin.EmailPlugin import EmailPlugin\n",
    "from Plugin.Time_Plugin import Time_Plugin\n",
    "from Plugin.WeatherPlugin import WeatherPlugin\n",
    "from Plugin.WaitPlugin import WaitPlugin\n",
    "from Plugin.ColorPlugin import ColorPlugin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kernel = Kernel()\n",
    "service_settings = ServiceSettings.create()\n",
    "# Remove all services so that this cell can be re-run without restarting the kernel\n",
    "kernel.remove_all_services()\n",
    "\n",
    "# Select a service to use for this notebook (available services: OpenAI, AzureOpenAI, HuggingFace)\n",
    "selectedService = (\n",
    "    Service.AzureOpenAI\n",
    "    if service_settings.global_llm_service is None\n",
    "    else Service(service_settings.global_llm_service.lower())\n",
    ")\n",
    "service_id = \"default\"\n",
    "kernel.add_service(AzureChatCompletion(service_id=service_id,),)\n",
    "kernel.add_plugin(EmailPlugin(),plugin_name=\"Email\",)\n",
    "kernel.add_plugin(Time_Plugin(),plugin_name=\"Time\",)\n",
    "kernel.add_plugin(WeatherPlugin(),plugin_name=\"Weather\",)\n",
    "kernel.add_plugin(WaitPlugin(),plugin_name=\"Wait\",)\n",
    "kernel.add_plugin(ColorPlugin(),plugin_name=\"Color\",)\n",
    "\n",
    "chat_completion : AzureChatCompletion = kernel.get_service(type=ChatCompletionClientBase)\n",
    "\n",
    "# Enable planning\n",
    "execution_settings = AzureChatPromptExecutionSettings(tool_choice=\"auto\")\n",
    "execution_settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current time is 2:17 PM on Sunday, September 8, 2024.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a history of the conversation\n",
    "history = ChatHistory()\n",
    "history.add_user_message(\"Can you tell me the time?\")\n",
    "\n",
    "result = (await chat_completion.get_chat_message_contents(\n",
    "        chat_history=history,\n",
    "        settings=execution_settings,\n",
    "        kernel=kernel,\n",
    "        arguments=KernelArguments(),\n",
    "    ))[0]\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in Boston is 61 degrees Fahrenheit with rainy conditions.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a history of the conversation\n",
    "history = ChatHistory()\n",
    "history.add_user_message(\"Can you tell me the weather in Boston?\")\n",
    "\n",
    "result = (await chat_completion.get_chat_message_contents(\n",
    "        chat_history=history,\n",
    "        settings=execution_settings,\n",
    "        kernel=kernel,\n",
    "        arguments=KernelArguments(),\n",
    "    ))[0]\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The color for Boston is red.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a history of the conversation\n",
    "history = ChatHistory()\n",
    "history.add_user_message(\"Can you tell me the color for Boston?\")\n",
    "\n",
    "result = (await chat_completion.get_chat_message_contents(\n",
    "        chat_history=history,\n",
    "        settings=execution_settings,\n",
    "        kernel=kernel,\n",
    "        arguments=KernelArguments(),\n",
    "    ))[0]\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in Boston is 61°F and rainy. The color associated with Boston is red.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a history of the conversation\n",
    "history = ChatHistory()\n",
    "history.add_user_message(\"Can you tell me the weather and color in Boston?\")\n",
    "\n",
    "result = (await chat_completion.get_chat_message_contents(\n",
    "        chat_history=history,\n",
    "        settings=execution_settings,\n",
    "        kernel=kernel,\n",
    "        arguments=KernelArguments(),\n",
    "    ))[0]\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current date and time is Sunday, September 8, 2024, at 2:18 PM.\n",
      "Please note that the time is based on the server's location and might differ from your local time.\n"
     ]
    }
   ],
   "source": [
    "# Create a history of the conversation\n",
    "history = ChatHistory()\n",
    "history.add_user_message(\"Can you tell me the time?\")\n",
    "\n",
    "result = (await chat_completion.get_chat_message_contents(\n",
    "        chat_history=history,\n",
    "        settings=execution_settings,\n",
    "        kernel=kernel,\n",
    "        arguments=KernelArguments(),\n",
    "    ))[0]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current local time in Boston is 02:18:41 PM, and the weather is 61°F with rain.\n"
     ]
    }
   ],
   "source": [
    "# Create a history of the conversation\n",
    "history = ChatHistory()\n",
    "history.add_user_message(\"Can you tell me the time and weather in Boston?\")\n",
    "\n",
    "result = (await chat_completion.get_chat_message_contents(\n",
    "        chat_history=history,\n",
    "        settings=execution_settings,\n",
    "        kernel=kernel,\n",
    "        arguments=KernelArguments(),\n",
    "    ))[0]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
