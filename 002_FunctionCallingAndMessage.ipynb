{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: if using a virtual environment, do not run this cell\n",
    "#%pip install -U semantic-kernel\n",
    "from semantic_kernel import __version__\n",
    "\n",
    "__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Kernel Test Notebook\n",
    "\n",
    "This notebook is intended to ensure you have semantic kernel setup on your enviornment.\n",
    "You should have a **.env** file that contains the following parameters that are used by semantic kernel\n",
    "\n",
    "This was tested on version 1.8.2 of Semantic Kernel\n",
    "\n",
    "```\n",
    "GLOBAL_LLM_SERVICE=\"AzureOpenAI\"\n",
    "AZURE_OPENAI_API_KEY=\"XXX\"\n",
    "AZURE_OPENAI_ENDPOINT=\"YYYY\"\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME=\"gpt-4o-global\"\n",
    "AZURE_OPENAI_TEXT_DEPLOYMENT_NAME=\"gpt-4o-global\"\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME=\"text-embedding-ada-002\"\n",
    "AZURE_OPENAI_API_VERSION=\"2024-05-01-preview\"\n",
    "##Semantic Kernel Settings:\n",
    "AZURE_AISEARCH_API_KEY=\"\"\n",
    "AZURE_AISEARCH_URL=\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from services import Service\n",
    "from service_settings import ServiceSettings\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.functions import KernelArguments\n",
    "\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.functions import kernel_function\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.connectors.ai.function_call_behavior import FunctionCallBehavior\n",
    "from semantic_kernel.connectors.ai.chat_completion_client_base import ChatCompletionClientBase\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "from semantic_kernel.functions.kernel_arguments import KernelArguments\n",
    "from semantic_kernel.connectors.ai.open_ai.prompt_execution_settings.azure_chat_prompt_execution_settings import (\n",
    "    AzureChatPromptExecutionSettings,\n",
    ")\n",
    "\n",
    "from semantic_kernel.contents import ChatMessageContent, TextContent, ImageContent\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "\n",
    "import os\n",
    "from Plugin.EmailPlugin import EmailPlugin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the Kernel\n",
    "Set up the kernel and add a plug in from a class that is an \"Email Plugin\"\n",
    "\n",
    "Its super basic.  The send_email function takes in a list of recieptns, subject and body.  \n",
    "The kernel will be smart enough to use chat to get that information in order to send an email\n",
    "\n",
    "```\n",
    "from semantic_kernel.functions import kernel_function\n",
    "from typing import List \n",
    "\n",
    "class EmailPlugin:\n",
    "    @kernel_function(\n",
    "        name=\"send_email\",\n",
    "        description=\"Sends an email to a recipient.\"\n",
    "    )\n",
    "    async def send_email(self, recipient_emails: str|List[str], subject: str, body: str):\n",
    "        # Add logic to send an email using the recipient_emails, subject, and body\n",
    "        # For now, we'll just print out a success message to the console\n",
    "        print(\"Email sent!\")\n",
    "        print(\"recipient_emails:\" + recipient_emails)\n",
    "        print(\"subject:\" + subject)\n",
    "        print(\"body:\" + body)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelPlugin(name='Email', description=None, functions={'send_email': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='send_email', plugin_name='Email', description='Sends an email to a recipient.', parameters=[KernelParameterMetadata(name='recipient_emails', description=None, default_value=None, type_='str, list[str]', is_required=True, type_object=None, schema_data={'anyOf': [{'type': 'string'}, {'type': 'object'}]}, function_schema_include=True), KernelParameterMetadata(name='subject', description=None, default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, function_schema_include=True), KernelParameterMetadata(name='body', description=None, default_value=None, type_='str', is_required=True, type_object=<class 'str'>, schema_data={'type': 'string'}, function_schema_include=True)], is_prompt=False, is_asynchronous=True, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='Any', is_required=True, type_object=None, schema_data={'type': 'object'}, function_schema_include=True), additional_properties={}), invocation_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x0000023615E1BC50>, streaming_duration_histogram=<opentelemetry.metrics._internal.instrument._ProxyHistogram object at 0x0000023614F1C290>, method=<bound method EmailPlugin.send_email of <Plugin.EmailPlugin.EmailPlugin object at 0x0000023617BB1410>>, stream_method=None)})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "kernel = Kernel()\n",
    "service_settings = ServiceSettings.create()\n",
    "# Remove all services so that this cell can be re-run without restarting the kernel\n",
    "kernel.remove_all_services()\n",
    "\n",
    "# Select a service to use for this notebook (available services: OpenAI, AzureOpenAI, HuggingFace)\n",
    "# selectedService = (\n",
    "#     Service.AzureOpenAI\n",
    "#     if service_settings.global_llm_service is None\n",
    "#     else Service(service_settings.global_llm_service.lower())\n",
    "# )\n",
    "service_id = \"default\"\n",
    "kernel.add_service(AzureChatCompletion(service_id=service_id,),)\n",
    "kernel.add_plugin(EmailPlugin(),plugin_name=\"Email\",)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference for Chat History:\n",
    "https://learn.microsoft.com/en-us/semantic-kernel/concepts/ai-services/chat-completion/chat-history?pivots=programming-language-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! I'd be happy to help you draft an email for your boss. To get started, I'll need a bit more information. Could you please provide the following details?\n",
      "\n",
      "1. The purpose of the email (meeting request, project update, issue report, proposal, etc.).\n",
      "2. The key points you want to include in the email.\n",
      "3. The tone you'd like to convey (formal, informal, urgent, etc.).\n",
      "4. Whether you need to include any attachments or links.\n",
      "5. The deadline, if applicable, for the response or action you're seeking.\n",
      "\n",
      "Once I have this information, I can help you compose a professional and effective email.\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "\n",
    "\n",
    "chat_completion : AzureChatCompletion = kernel.get_service(type=ChatCompletionClientBase)\n",
    "\n",
    "# Enable planning\n",
    "execution_settings = AzureChatPromptExecutionSettings(tool_choice=\"auto\")\n",
    "execution_settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "# Create a history of the conversation\n",
    "history = ChatHistory()\n",
    "history.add_system_message(\"You are a helpful assistant.\")\n",
    "history.add_user_message(\"Can you help me write an email for my boss?\")\n",
    "\n",
    "result = (await chat_completion.get_chat_message_contents(\n",
    "        chat_history=history,\n",
    "        settings=execution_settings,\n",
    "        kernel=kernel,\n",
    "        arguments=KernelArguments(),\n",
    "    ))[0]\n",
    "print(result)\n",
    "\n",
    "\n",
    "history.add_assistant_message(str(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here's a draft for your email:\n",
      "\n",
      "Subject: Azure is Super Cool\n",
      "\n",
      "Dear [Boss's Name],\n",
      "\n",
      "I hope this message finds you well.\n",
      "\n",
      "I am writing to share my excitement about the powerful capabilities of Azure AI that we've started leveraging in our recent projects. The suite of advanced analytics and machine-learning services that Azure provides is truly impressive, and it brings a new level of efficiency and innovation to our workflows.\n",
      "\n",
      "I wanted to assure you that I'm fully immersed in maximizing the potential of these tools. The impact on our productivity and decision-making is already noticeable, and I'm confident that it's going to be a game-changer for us.\n",
      "\n",
      "Please rest easy knowing that everything is under control and progressing smoothly. Of course, I'll keep you updated on our milestones and any significant achievements as we continue to explore this cutting-edge technology.\n",
      "\n",
      "If you have any questions or wish to discuss this further, please don't hesitate to reach out. Your insights are always valued and appreciated.\n",
      "\n",
      "Thank you for your support, and look forward to bringing more positive updates to your attention.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n",
      "[Your Position]\n",
      "\n",
      "Please modify \"[Boss's Name]\", \"[Your Name]\", and \"[Your Position]\" with the relevant details. If this email meets your expectations, you can send it to your boss, or let me know if there are any adjustments you'd like to make.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "history.add_user_message(\"subject: Azure is Super Cool, main points: azure ai is very powerful.  My boss doesn't need to do anything, I've got this.  Use a semi-formal tone.\")\n",
    "\n",
    "result = (await chat_completion.get_chat_message_contents(\n",
    "        chat_history=history,\n",
    "      \n",
    "        settings=execution_settings,\n",
    "        kernel=kernel,\n",
    "        arguments=KernelArguments(),\n",
    "    ))[0]\n",
    "print(result)\n",
    "\n",
    "\n",
    "history.add_assistant_message(str(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email sent!\n",
      "recipient_emails:boss@gmail.com\n",
      "subject:Azure is Super Cool\n",
      "body:Dear Boss,\n",
      "\n",
      "I hope this message finds you well.\n",
      "\n",
      "I am writing to share my excitement about the powerful capabilities of Azure AI that we've started leveraging in our recent projects. The suite of advanced analytics and machine-learning services that Azure provides is truly impressive, and it brings a new level of efficiency and innovation to our workflows.\n",
      "\n",
      "I wanted to assure you that I'm fully immersed in maximizing the potential of these tools. The impact on our productivity and decision-making is already noticeable, and I'm confident that it's going to be a game-changer for us.\n",
      "\n",
      "Please rest easy knowing that everything is under control and progressing smoothly. Of course, I'll keep you updated on our milestones and any significant achievements as we continue to explore this cutting-edge technology.\n",
      "\n",
      "If you have any questions or wish to discuss this further, please don't hesitate to reach out. Your insights are always valued and appreciated.\n",
      "\n",
      "Thank you for your support, and look forward to bringing more positive updates to your attention.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n",
      "[Your Position]\n",
      "The email has been sent to your boss at boss@gmail.com with the subject \"Azure is Super Cool\". If there's anything else I can assist you with, feel free to let me know!\n"
     ]
    }
   ],
   "source": [
    "history.add_user_message(\"ok, boss's email: boss@gmail.com, please send it to her.\")\n",
    "\n",
    "result = (await chat_completion.get_chat_message_contents(\n",
    "        chat_history=history,\n",
    "      \n",
    "        settings=execution_settings,\n",
    "        kernel=kernel,\n",
    "        arguments=KernelArguments(),\n",
    "    ))[0]\n",
    "print(result)\n",
    "\n",
    "history.add_assistant_message(str(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving on...\n",
    "We can ask for a joke, but this is not using the joke template taht we did in 001_tester.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't skeletons fight each other? \n",
      "\n",
      "They don't have the guts. 😄\n"
     ]
    }
   ],
   "source": [
    "history.add_user_message(\"tell me a joke\")\n",
    "\n",
    "result = (await chat_completion.get_chat_message_contents(\n",
    "        chat_history=history,\n",
    "      \n",
    "        settings=execution_settings,\n",
    "        kernel=kernel,\n",
    "        arguments=KernelArguments(),\n",
    "    ))[0]\n",
    "print(result)\n",
    "history.add_assistant_message(str(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system:You are a helpful assistant.\n",
      "user:Can you help me write an email for my boss?\n",
      "assistant:Of course! I'd be happy to help you draft an email for your boss. To get started, I'll need a bit more information. Could you please provide the following details?\n",
      "\n",
      "1. The purpose of the email (meeting request, project update, issue report, proposal, etc.).\n",
      "2. The key points you want to include in the email.\n",
      "3. The tone you'd like to convey (formal, informal, urgent, etc.).\n",
      "4. Whether you need to include any attachments or links.\n",
      "5. The deadline, if applicable, for the response or action you're seeking.\n",
      "\n",
      "Once I have this information, I can help you compose a professional and effective email.\n",
      "user:subject: Azure is Super Cool, main points: azure ai is very powerful.  My boss doesn't need to do anything, I've got this.  Use a semi-formal tone.\n",
      "user:subject: Azure is Super Cool, main points: azure ai is very powerful.  My boss doesn't need to do anything, I've got this.  Use a semi-formal tone.\n",
      "assistant:Certainly! Here's a draft for your email:\n",
      "\n",
      "Subject: Azure is Super Cool\n",
      "\n",
      "Dear [Boss's Name],\n",
      "\n",
      "I hope this message finds you well.\n",
      "\n",
      "I am writing to share my excitement about the powerful capabilities of Azure AI that we've started leveraging in our recent projects. The suite of advanced analytics and machine-learning services that Azure provides is truly impressive, and it brings a new level of efficiency and innovation to our workflows.\n",
      "\n",
      "I wanted to assure you that I'm fully immersed in maximizing the potential of these tools. The impact on our productivity and decision-making is already noticeable, and I'm confident that it's going to be a game-changer for us.\n",
      "\n",
      "Please rest easy knowing that everything is under control and progressing smoothly. Of course, I'll keep you updated on our milestones and any significant achievements as we continue to explore this cutting-edge technology.\n",
      "\n",
      "If you have any questions or wish to discuss this further, please don't hesitate to reach out. Your insights are always valued and appreciated.\n",
      "\n",
      "Thank you for your support, and look forward to bringing more positive updates to your attention.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n",
      "[Your Position]\n",
      "\n",
      "Please modify \"[Boss's Name]\", \"[Your Name]\", and \"[Your Position]\" with the relevant details. If this email meets your expectations, you can send it to your boss, or let me know if there are any adjustments you'd like to make.\n",
      "user:ok, boss's email: boss@gmail.com, please send it to her.\n",
      "assistant:\n",
      "tool:\n",
      "assistant:The email has been sent to your boss at boss@gmail.com with the subject \"Azure is Super Cool\". If there's anything else I can assist you with, feel free to let me know!\n",
      "user:tell me a joke\n",
      "assistant:Why don't skeletons fight each other? \n",
      "\n",
      "They don't have the guts. 😄\n"
     ]
    }
   ],
   "source": [
    "for msg in history.messages:\n",
    "    print(msg.role + \":\" + msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
